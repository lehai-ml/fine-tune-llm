{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfmlQVYvH5Jq7S3vlFcwnn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehai-ml/fine-tune-llm/blob/main/nlp_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP tasks with Hugging Face"
      ],
      "metadata": {
        "id": "dm3bDA124bpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The full guide of huggingface is found here [[1]](https://huggingface.co/learn/llm-course/chapter1/1?fw=pt). This is a review of the main concepts along with some codes.\n",
        "\n",
        "* Natural language processing (NLP) - refers to the field focused on enabling computers to understand, interpret and generate human language.\n",
        "* Large language models (LLMs) - subset of NLPs and are trained on a massive dataset. Models example are Llama and ChatGPT\n",
        "\n",
        "\n",
        "Some NLP tasks include:\n",
        "1. Classifying the whole senteces - e.g., sentiment analysis\n",
        "2. Classifying individual word - e.g., named entity extraction\n",
        "3. Question and answering - given a question and context, extract a factually correct answer.\n",
        "4. Generating text content\n",
        "5. Translation\n",
        "\n",
        "Development of LLMs also means that we can now have seemingly all-knowing chatbot. However, some of the problems associated with LLMs are:\n",
        "* Hallucination - where the model will provide with ostensibly correct-sounding answer, that is in fact wrong.\n",
        "* Bias\n",
        "* Lack of reasoning\n",
        "* Computational resources"
      ],
      "metadata": {
        "id": "eZtGa2YN5-Sa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Transformers\n",
        "\n",
        "Transformers is a type of architecture that underlies many of the well-known NLP models. This video by [3Blue1Brown](https://www.youtube.com/watch?v=wjZofJX0v4M) explains it quite well.\n",
        "\n",
        "In a nutshell, a transformer is consisted of several layers, with each layer feeding information to the next. In the case of the Generative pre-trained transformer (GPT), a piece of text is fed to the transformer, and the transformer will output the next most probable word based on the input of all previous words.\n",
        "\n",
        "The transformer library of huggingface is very versatile. `pipeline` object allows one to use a variety of pretrained models for different tasks, including:\n",
        "* `text-generation`\n",
        "* `text-classification`\n",
        "* `summarization`\n",
        "* `translation`\n",
        "* `zero-shot-classification`\n",
        "* `feature-extraction`\n",
        "* `image-to-text`\n",
        "* `image-classfication`\n",
        "* `object-detection`\n",
        "* `automatic-speech-recognition`\n",
        "* `audio-classification`\n",
        "* `text-to-speech`\n",
        "* `image-text-to-text`"
      ],
      "metadata": {
        "id": "u-taZ9068TTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n"
      ],
      "metadata": {
        "id": "cz6NGClEiA-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"Four legged animal with fur, and can be found mummified in egypt\",\n",
        "    candidate_labels=[\"dog\",\"cat\",\"chicken\"],\n",
        ")\n"
      ],
      "metadata": {
        "id": "wqgSkneKiP_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformers architecture\n",
        "\n",
        "Transformers are *language models*, meaning they can be trained in a self-supervised manner.\n",
        "\n",
        "Self-supervised learning is type of learning where the objective is computed from the input. For example, you crop a part of the image and you let the model predict that part of the image. In the case of NLP, this can be either predicting the next word after reading *n* numbers of words (*causal language modeling*), or predicting a masked input (*masked language modeling*). These are also known as auxiliary tasks or pretext tasks; you don't really care about the performance of these tasks, but rather you use this as a pretext for the model to learn about intrisic relationship between the input (e.g., semantic relationship or position of the pixels within the image) [[3]](https://lilianweng.github.io/posts/2019-11-10-self-supervised/). These pretrained models are useful when are fine-tuned (using transfer learning) to a specific tasks."
      ],
      "metadata": {
        "id": "1N3uUuQkjgYG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHB831lbsUIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hfKru56RsUFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-B2hMGcjEF-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}